{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last eigenvalue in the row with 'Alpha occ. eigenvalues': -0.28477\n",
      "First value in the row with 'Alpha virt.': -0.03704\n",
      "Last eigenvalue in the row with 'Alpha occ. eigenvalues': -0.28610\n",
      "First value in the row with 'Alpha virt.': -0.03923\n",
      "Last eigenvalue in the row with 'Alpha occ. eigenvalues': -0.28610\n",
      "First value in the row with 'Alpha virt.': -0.03923\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "infile = \"low_energy/ph3ph35cf3_3_1_m062x.log\"\n",
    "\n",
    "\n",
    "\n",
    "def find_alpha_occ_and_virt_eigenvalues(file_path):\n",
    "    try:\n",
    "        with open(file_path, 'r') as file:\n",
    "            last_eigenvalue = None\n",
    "\n",
    "            for line in file:\n",
    "                # Check if the line contains 'Alpha occ. eigenvalues'\n",
    "                if ' Alpha  occ.' in line:\n",
    "                    # Split the line into elements and extract the last one\n",
    "                    eigenvalues = line.split()\n",
    "                    last_eigenvalue = eigenvalues[-1]\n",
    "                \n",
    "                # Check if the next line starts with 'Alpha virt.'\n",
    "                elif last_eigenvalue is not None and line.startswith(' Alpha virt.'):\n",
    "                    # Print the last eigenvalue only if the next line starts with 'Alpha virt.'\n",
    "                    virt_values = line.split()\n",
    "                    first_virt_value = virt_values[4]\n",
    "\n",
    "                    # Print both the last eigenvalue and the first value in 'Alpha virt.'\n",
    "                    print(f\"Last eigenvalue in the row with 'Alpha occ. eigenvalues': {last_eigenvalue}\")\n",
    "                    print(f\"First value in the row with 'Alpha virt.': {first_virt_value}\")\n",
    "\n",
    "                    last_eigenvalue = None\n",
    "    except Exception as e:\n",
    "            print(f\"An error occurred: {e}\")\n",
    "\n",
    "\n",
    "# Replace 'your_file.txt' with the actual path to your text file\n",
    "find_alpha_occ_and_virt_eigenvalues(infile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def find_alpha_occ_and_virt_eigenvalues(file_path):\n",
    "    try:\n",
    "        with open(file_path, 'r') as file:\n",
    "            last_eigenvalue = None\n",
    "\n",
    "            for line in file:\n",
    "                # Check if the line contains 'Alpha occ. eigenvalues'\n",
    "                if ' Alpha  occ.' in line:\n",
    "                    # Split the line into elements and extract the last one\n",
    "                    eigenvalues = line.split()\n",
    "                    last_eigenvalue = eigenvalues[-1]\n",
    "                \n",
    "                # Check if the next line starts with 'Alpha virt.'\n",
    "                elif last_eigenvalue is not None and line.startswith(' Alpha virt.'):\n",
    "                    # Split the line into elements and extract the first one\n",
    "                    virt_values = line.split()\n",
    "                    first_virt_value = virt_values[4]\n",
    "\n",
    "                    # Return both the last eigenvalue and the first value in 'Alpha virt.'\n",
    "                    return last_eigenvalue, first_virt_value\n",
    "\n",
    "            # If the function reaches this point, it means 'Alpha occ. eigenvalues' was not found\n",
    "            return None, None\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        return None, None\n",
    "\n",
    "def process_files_in_folder(folder_path, output_file_path):\n",
    "    try:\n",
    "        with open(output_file_path, 'w') as output_file:\n",
    "            # Iterate over all files in the folder\n",
    "            for filename in os.listdir(folder_path):\n",
    "                if filename.endswith(\".log\"):\n",
    "                    file_path = os.path.join(folder_path, filename)\n",
    "                    \n",
    "                    # Apply the function to the current file\n",
    "                    last_eigenvalue, first_virt_value = find_alpha_occ_and_virt_eigenvalues(file_path)\n",
    "                    \n",
    "                    # Write the results to the output file along with the file name\n",
    "                    output_file.write(f\"File: {filename} ,   {last_eigenvalue} ,    {first_virt_value}\\n\")\n",
    "                    #output_file.write(f\"Last eigenvalue: {last_eigenvalue}\\n\")\n",
    "                    #output_file.write(f\"First value in 'Alpha virt.': {first_virt_value}\\n\\n\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "\n",
    "# Replace 'your_folder_path' with the actual path to your folder containing .log files\n",
    "folder_path = 'low_energy/'\n",
    "# Replace 'output.txt' with the desired output file path\n",
    "output_file_path = 'new_output.txt'\n",
    "\n",
    "process_files_in_folder(folder_path, output_file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_polarizabilities(file_path):\n",
    "    try:\n",
    "        with open(file_path, 'r') as file:\n",
    "            exact_polarizabilities = []\n",
    "            isotropic_polarizabilities = []\n",
    "\n",
    "            for line in file:\n",
    "                # Check if the line starts with 'Exact polarizability'\n",
    "                if line.startswith('  Exact polarizability'):\n",
    "                    # Split the line into elements and extract the values\n",
    "                    polarizabilities = line.split()[2:]\n",
    "                    exact_polarizabilities.extend(map(float, polarizabilities))\n",
    "                \n",
    "                # Check if the line starts with 'Isotropic polarizability'\n",
    "                elif line.startswith(' Isotropic polarizability'):\n",
    "                    # Split the line into elements and extract the values\n",
    "                    polarizabilities = line.split()[3:]\n",
    "                    isotropic_polarizabilities.extend(polarizabilities)\n",
    "\n",
    "            # Return the extracted values\n",
    "            return (\n",
    "                ', '.join(map(str, exact_polarizabilities)),\n",
    "                isotropic_polarizabilities\n",
    "            )\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        return None, None\n",
    "\n",
    "def process_files_in_folder(folder_path, output_file_path):\n",
    "    try:\n",
    "        with open(output_file_path, 'w') as output_file:\n",
    "            # Iterate over all files in the folder\n",
    "            for filename in os.listdir(folder_path):\n",
    "                if filename.endswith(\".log\"):\n",
    "                    file_path = os.path.join(folder_path, filename)\n",
    "                    \n",
    "                    # Extract polarizabilities from the current file\n",
    "                    exact_polarizabilities, isotropic_polarizabilities = extract_polarizabilities(file_path)\n",
    "                    \n",
    "                    # Write the results to the output file along with the file name\n",
    "                    output_file.write(f\"File: {filename} ,  {exact_polarizabilities},  {isotropic_polarizabilities[2]}\\n\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "\n",
    "# Replace 'your_folder_path' with the actual path to your folder containing .log files\n",
    "# Replace 'output.txt' with the desired output file path\n",
    "output_file_path = 'n_polar.txt'\n",
    "\n",
    "process_files_in_folder(\"./\", output_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['File: ph_2triphenylene_2_1_m062x.log ', ' 3 ', ' 7\\n']\n",
      "['File: ph_fluorene_cyclobutyl_4_1_m062x.log ', '3 ', ' 7\\n']\n",
      "['File: ph_2hydropyrenemethyl_3_m062x.log ', ' 39 ', ' 2\\n']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def extract_values_after_line(file_path, target_line, val):\n",
    "    try:\n",
    "            with open(file_path, 'r') as file:\n",
    "                values = []\n",
    "                found_target_line = False\n",
    "            \n",
    "                rows_after_target_line = 0\n",
    "\n",
    "                for line in file:\n",
    "                    # Check if the line contains the target line\n",
    "                    if target_line in line:\n",
    "                        found_target_line = True\n",
    "\n",
    "                    # Extract values from the 4th row after finding the target line\n",
    "                    elif found_target_line:\n",
    "                        # Increment the count of rows after the target line\n",
    "                        rows_after_target_line += 1\n",
    "\n",
    "                        # Extract values from the 4th row\n",
    "                        if rows_after_target_line == val+1:\n",
    "                            # Split the line into elements and extract the value from the 4th column\n",
    "                            columns = line.split()\n",
    "                            if len(columns) >= 4:\n",
    "                                value = columns[2:]\n",
    "                                values.extend(map(float, value))\n",
    "                            break  # Stop extracting values after the 4th row\n",
    "\n",
    "            # Return the extracted values\n",
    "            return (\n",
    "                ', '.join(map(str, values))\n",
    "                \n",
    "            )\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        return None\n",
    "def extract_info_from_id_file(id_file_path):\n",
    "    filenames = []\n",
    "    IDs = []\n",
    "    try:\n",
    "        with open(id_file_path, 'r') as id_file:\n",
    "            for line in id_file:\n",
    "                \n",
    "                # Split the line into elements and extract information\n",
    "                elements = line.split(',')\n",
    "                if len(elements) ==3 :\n",
    "                    print(elements)\n",
    "                    # Extract file name and integers\n",
    "                    file_name = elements[0].strip().replace(' ', '').replace('File:', '')\n",
    "                    integer1 = int(elements[1].strip())\n",
    "                    integer2 = int(elements[2].strip().replace('\\n', ''))\n",
    "                    filenames.append(file_name)\n",
    "                    IDs.append([integer1, integer2] )\n",
    "                    # Print the extracted information\n",
    "        return filenames, IDs\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "def process_files_in_folder(folder_path, output_file_path,  id_file_path):\n",
    "    filenames,IDs = extract_info_from_id_file(id_file_path)\n",
    "    try:\n",
    "        with open(output_file_path, 'w') as output_file:\n",
    "            # Iterate over all files in the folder\n",
    "\n",
    "            for i in range(len(filenames)):\n",
    "                filename= filenames[i]\n",
    "                vals = IDs[i]\n",
    "                if filename.endswith(\".log\"):\n",
    "                    file_path = os.path.join(folder_path, filename)\n",
    "                    \n",
    "                    # Extract values after the specified line from the current file\n",
    "                    target_line = '    Atom  No    Charge         Core      Valence    Rydberg      Total'\n",
    "                    for val in vals:\n",
    "                        extracted_values = extract_values_after_line(file_path, target_line, val)\n",
    "                    \n",
    "                    # Write the results to the output file along with the file name\n",
    "                        output_file.write(f\"{filename} atom {val}, {extracted_values} , \")\n",
    "                    output_file.write(\"\\n\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "\n",
    "# Replace 'your_folder_path' with the actual path to your folder containing .log files\n",
    "# Replace 'output.txt' with the desired output file path\n",
    "output_file_path = 'n_NBO.txt'\n",
    "\n",
    "process_files_in_folder(\"./\", output_file_path, \"Atom_IDs_new.txt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['File: ph4cf3_idp_2_1_m062x.log   ', '1 ', ' 15\\n']\n",
      "['File: ph_fluorene_methyl_1_1_m062x.log ', ' 27 ', ' 14\\n']\n",
      "['File: ph_35prf_37_1_m062x.log ', ' 6 ', ' 14\\n']\n",
      "['File: ph_35et_5_1_m062x.log ', ' 6 ', ' 14\\n']\n",
      "['File: 1naphth_idp_1_1_m062x.log ', ' 4', ' 1\\n']\n",
      "['File: ph_fluorene_cy_idp_1_1_m062x.log ', ' 1 ', ' 14\\n']\n",
      "['File: ph_4ph_3_1_m062x.log ', '6 ', ' 14\\n']\n",
      "['File: 2naphth_idp_1_1_m062x.log', ' 5', ' 1\\n']\n",
      "['File: ph_pyrene_me_1_1_m062x.log ', ' 4 ', '14\\n']\n",
      "['File: phenyl_idp_1_1_m062x.log ', ' 1', ' 7\\n']\n",
      "['File: ph4tbu_idp_1_1_m062x.log ', ' 1 ', '15\\n']\n",
      "['File: ph35cf3_1_1_m062x.log ', ' 1 ', '15\\n']\n",
      "['File: ph_fluorene_cp_nbutyl_63_1_m062x.log ', ' 36 ', ' 15\\n']\n",
      "['File: ph_4me_2_1_m062x.log ', ' 6 ', '  14\\n']\n",
      "['File: ph_fluorene_cp_phenyl_idp_8_1_m062x.log ', ' 1 ', '14\\n']\n",
      "['File: ph_35pr_41_1_m062x.log ', ' 6 ', ' 14\\n']\n",
      "['File: ph_35iprf_6_1_m062x.log ', ' 6 ', ' 14\\n']\n",
      "['File: ph_35hex_154_1_m062x.log ', ' 6 ', ' 14\\n']\n",
      "['File: ph_fluorene_cp_tbutyl_10_1_m062x.log ', ' 36 ', ' 15\\n']\n",
      "['File: ph_fluorene_cp_7_1_m062x.log ', ' 35 ', ' 14\\n']\n",
      "['File: ph_35me_2_1_m062x.log ', ' 6 ', ' 14\\n']\n",
      "['File: ph_345me_1_1_m062x.log ', ' 6 ', ' 14\\n']\n",
      "['File: ph_3ph4cf3_8_1_m062x.log ', ' 1 ', '14\\n']\n",
      "['File: ph_35isopbutyl_38_1_m062x.log ', ' 6', ' 14\\n']\n",
      "['File: ph_2phenanthryl_2_1_m062x.log ', ' 4 ', '14\\n']\n",
      "['File: ph35sf5_idp_7_1_m062x.log ', ' 1', ' 14\\n']\n",
      "['File: ph_fluorene_cp_methyl_idp_8_1_m062x.log ', ' 36 ', ' 15\\n']\n",
      "['File: ph_fluorene_cp_methyl_idp_1_1_m062x.log ', ' 36 ', ' 15\\n']\n",
      "['File: ph4sf5_2_1_m062x.log ', ' 1', ' 14\\n']\n",
      "An error occurred: local variable 'value1' referenced before assignment\n",
      "An error occurred: unsupported operand type(s) for -: 'list' and 'list'\n",
      "An error occurred: local variable 'value4' referenced before assignment\n",
      "An error occurred: local variable 'value4' referenced before assignment\n",
      "An error occurred: local variable 'value2' referenced before assignment\n",
      "An error occurred: local variable 'value1' referenced before assignment\n",
      "An error occurred: local variable 'value4' referenced before assignment\n",
      "An error occurred: local variable 'value4' referenced before assignment\n",
      "An error occurred: unsupported operand type(s) for -: 'list' and 'list'\n",
      "An error occurred: local variable 'value1' referenced before assignment\n",
      "An error occurred: local variable 'value1' referenced before assignment\n",
      "An error occurred: local variable 'value1' referenced before assignment\n",
      "An error occurred: unsupported operand type(s) for -: 'list' and 'list'\n",
      "An error occurred: local variable 'value4' referenced before assignment\n",
      "An error occurred: local variable 'value1' referenced before assignment\n",
      "An error occurred: local variable 'value4' referenced before assignment\n",
      "An error occurred: local variable 'value4' referenced before assignment\n",
      "An error occurred: local variable 'value4' referenced before assignment\n",
      "An error occurred: unsupported operand type(s) for -: 'list' and 'list'\n",
      "An error occurred: unsupported operand type(s) for -: 'list' and 'list'\n",
      "An error occurred: local variable 'value4' referenced before assignment\n",
      "An error occurred: local variable 'value4' referenced before assignment\n",
      "An error occurred: local variable 'value1' referenced before assignment\n",
      "An error occurred: local variable 'value4' referenced before assignment\n",
      "An error occurred: unsupported operand type(s) for -: 'list' and 'list'\n",
      "An error occurred: local variable 'value1' referenced before assignment\n",
      "An error occurred: local variable 'value2' referenced before assignment\n",
      "An error occurred: local variable 'value2' referenced before assignment\n",
      "An error occurred: local variable 'value1' referenced before assignment\n"
     ]
    }
   ],
   "source": [
    "def calc_dihedral(u1, u2, u3, u4):\n",
    "    \"\"\" Calculate dihedral angle method. From bioPython.PDB\n",
    "    (adapted to np.array)\n",
    "    Calculate the dihedral angle between 4 vectors\n",
    "    representing 4 connected points. The angle is in\n",
    "    [-pi, pi].\n",
    "    \"\"\"\n",
    "\n",
    "    a1 = u2 - u1\n",
    "    a2 = u3 - u2\n",
    "    a3 = u4 - u3\n",
    "\n",
    "    v1 = np.cross(a1, a2)\n",
    "    v1 = v1 / (v1 * v1).sum(-1)**0.5\n",
    "    v2 = np.cross(a2, a3)\n",
    "    v2 = v2 / (v2 * v2).sum(-1)**0.5\n",
    "    porm = np.sign((v1 * a3).sum(-1))\n",
    "    rad = np.arccos((v1*v2).sum(-1) / ((v1**2).sum(-1) * (v2**2).sum(-1))**0.5)\n",
    "    if not porm == 0:\n",
    "        rad = rad * porm\n",
    "\n",
    "    return rad\n",
    "def extract_values_after_last_occurrence(file_path, target_line,vals):\n",
    "    try:\n",
    "        with open(file_path, 'r') as file:\n",
    "            values = []\n",
    "            found_target_line = False\n",
    "            rows_after_target_line = 0\n",
    "\n",
    "            for line in reversed(file.readlines()):\n",
    "                # Check if the line contains the target line\n",
    "                if target_line in line:\n",
    "                    found_target_line = True\n",
    "\n",
    "                # Extract values from the 4th row after the last occurrence of the target line\n",
    "                elif found_target_line:\n",
    "                    # Increment the count of rows after the target line\n",
    "                    \n",
    "                    rows_after_target_line += 1\n",
    "                    if rows_after_target_line == vals[1]+1:\n",
    "                            columns = line.split()\n",
    "                            if len(columns) >= 4:\n",
    "                                value2 = columns[3:]\n",
    "                            \n",
    " # Stop extracting values after the 4th row\n",
    "                    elif rows_after_target_line == vals[0]+1:\n",
    "                            # Split the line into elements and extract the value from the 4th column\n",
    "                            columns = line.split()\n",
    "                            if len(columns) >= 4:\n",
    "                                value1 = columns[3:]\n",
    "                    elif rows_after_target_line == vals[0]:\n",
    "                            # Split the line into elements and extract the value from the 4th column\n",
    "                            columns = line.split()\n",
    "                            if len(columns) >= 4:\n",
    "                                value3 = columns[3:]            \n",
    "                    elif rows_after_target_line == vals[0]+2:\n",
    "                            # Split the line into elements and extract the value from the 4th column\n",
    "                            columns = line.split()\n",
    "                            if len(columns) >= 4:\n",
    "                                value4 = columns[3:]\n",
    "                    elif rows_after_target_line == vals[1]:\n",
    "                            # Split the line into elements and extract the value from the 4th column\n",
    "                            columns = line.split()\n",
    "                            if len(columns) >= 4:\n",
    "                                value5 = columns[3:]\n",
    "                    elif rows_after_target_line == vals[1]+2:\n",
    "                            # Split the line into elements and extract the value from the 4th column\n",
    "                            columns = line.split()\n",
    "                            if len(columns) >= 4:\n",
    "                                value6 = columns[3:]\n",
    "                            \n",
    "            dih=np.min(abs(calc_dihedral(value4, value1, value2, value6)),abs(calc_dihedral(value1, value1, value2, value5)))\n",
    "            # Return the extracted values\n",
    "            return dih\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        return None\n",
    "\n",
    "def process_files_in_folder(folder_path, output_file_path,id_file_path):\n",
    "    filenames,IDs = extract_info_from_id_file(id_file_path)\n",
    "    try:\n",
    "        with open(output_file_path, 'w') as output_file:\n",
    "            # Iterate over all files in the folder\n",
    "\n",
    "            for i in range(len(filenames)):\n",
    "                filename= filenames[i]\n",
    "                vals = IDs[i]\n",
    "                if filename.endswith(\".log\"):\n",
    "                    file_path = os.path.join(folder_path, filename)\n",
    "                    target_line = ' Center     Atomic      Atomic             Coordinates (Angstroms)'\n",
    "                    extracted_values = extract_values_after_last_occurrence(file_path, target_line,vals)\n",
    "                    \n",
    "                    # Write the results to the output file along with the file name\n",
    "                    output_file.write(f\"File: {filename}\\n\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "\n",
    "# Replace 'output.txt' with the desired output file path\n",
    "output_file_path = 'dih.txt'\n",
    "\n",
    "process_files_in_folder(folder_path, output_file_path,\"Atom_IDs.txt\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMILES representation of the molecule: C1CCC(C2CCC3C4CCCCC4C4(CCCCC4)C3C2)CC1\n"
     ]
    }
   ],
   "source": [
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "\n",
    "def pdb_to_smiles(pdb_file_path):\n",
    "    # Load the PDB file\n",
    "    mol= Chem.MolFromPDBFile(pdb_file_path)\n",
    "    \n",
    "    # Generate 2D coordinates\n",
    "    AllChem.Compute2DCoords(mol)\n",
    "    Chem.Kekulize(mol, clearAromaticFlags=False)\n",
    "    # Get the molecule\n",
    "    #mol = next(mol)\n",
    "    \n",
    "    # Generate SMILES\n",
    "    smiles = Chem.MolToSmiles(mol)\n",
    "    \n",
    "    return smiles\n",
    "\n",
    "# Replace 'your_molecule.pdb' with the actual path to your PDB file\n",
    "pdb_file_path = 'low_energy/ph_fluorene_cy_idp_1_1_m062x.pdb'\n",
    "\n",
    "try:\n",
    "    molecule_smiles = pdb_to_smiles(pdb_file_path)\n",
    "    print(f\"SMILES representation of the molecule: {molecule_smiles}\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMILES representation of the molecule: c1ccc(cc1)c1ccc2-c3c(C4(c2c1)CCCCC4)cccc3\tlow_energy/ph_fluorene_cy_idp_1_1_m062x.log\n"
     ]
    }
   ],
   "source": [
    "from openbabel import pybel\n",
    "def gaussian_output_to_smiles(gaussian_output_file):\n",
    "    try:\n",
    "        # Read Gaussian output file using Open Babel\n",
    "        mol = next(pybel.readfile(\"g09\", gaussian_output_file))\n",
    "        \n",
    "        # Generate SMILES\n",
    "        smiles = mol.write(\"can\").strip()\n",
    "        \n",
    "        return smiles\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        return None\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "pdb_file_path = 'low_energy/ph_fluorene_cy_idp_1_1_m062x.log'\n",
    "\n",
    "try:\n",
    "    molecule_smiles = gaussian_output_to_smiles(pdb_file_path)\n",
    "    print(f\"SMILES representation of the molecule: {molecule_smiles}\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File: ph4cf3_idp_2_1_m062x.log, SMILES: FC(c1ccc(cc1)c1ccccc1)(F)F\tlow_energy/ph4cf3_idp_2_1_m062x.log\n",
      "File: ph_fluorene_methyl_1_1_m062x.log, SMILES: CC1(C)c2cc(ccc2-c2c1cccc2)c1ccccc1\tlow_energy/ph_fluorene_methyl_1_1_m062x.log\n",
      "File: ph_35prf_37_1_m062x.log, SMILES: FC(C(C(c1cc(cc(c1)C(C(C(F)(F)F)(F)F)(F)F)c1ccccc1)(F)F)(F)F)(F)F\tlow_energy/ph_35prf_37_1_m062x.log\n",
      "File: ph_35et_5_1_m062x.log, SMILES: CCc1cc(CC)cc(c1)c1ccccc1\tlow_energy/ph_35et_5_1_m062x.log\n",
      "File: 1naphth_idp_1_1_m062x.log, SMILES: c1ccc(cc1)c1cccc2c1cccc2\tlow_energy/1naphth_idp_1_1_m062x.log\n",
      "File: ph_fluorene_cy_idp_1_1_m062x.log, SMILES: c1ccc(cc1)c1ccc2-c3c(C4(c2c1)CCCCC4)cccc3\tlow_energy/ph_fluorene_cy_idp_1_1_m062x.log\n",
      "File: ph_4ph_3_1_m062x.log, SMILES: c1ccc(cc1)c1ccc(cc1)c1ccccc1\tlow_energy/ph_4ph_3_1_m062x.log\n",
      "File: 2naphth_idp_1_1_m062x.log, SMILES: c1ccc(cc1)c1ccc2c(c1)cccc2\tlow_energy/2naphth_idp_1_1_m062x.log\n",
      "File: ph_pyrene_me_1_1_m062x.log, SMILES: Cc1cc(C)c2c3c1ccc1c3c(cc2)cc(c1)c1ccccc1\tlow_energy/ph_pyrene_me_1_1_m062x.log\n",
      "File: phenyl_idp_1_1_m062x.log, SMILES: c1ccc(cc1)c1ccccc1\tlow_energy/phenyl_idp_1_1_m062x.log\n",
      "File: ph4tbu_idp_1_1_m062x.log, SMILES: CC(c1ccc(cc1)c1ccccc1)(C)C\tlow_energy/ph4tbu_idp_1_1_m062x.log\n",
      "File: ph35cf3_1_1_m062x.log, SMILES: FC(c1cc(cc(c1)c1ccccc1)C(F)(F)F)(F)F\tlow_energy/ph35cf3_1_1_m062x.log\n",
      "File: ph_fluorene_cp_nbutyl_63_1_m062x.log, SMILES: CCCCc1ccc2-c3c(C4(c2c1)CCCC4)cc(cc3)c1ccccc1\tlow_energy/ph_fluorene_cp_nbutyl_63_1_m062x.log\n",
      "File: ph_4me_2_1_m062x.log, SMILES: Cc1ccc(cc1)c1ccccc1\tlow_energy/ph_4me_2_1_m062x.log\n",
      "File: ph_fluorene_cp_phenyl_idp_8_1_m062x.log, SMILES: c1ccc(cc1)c1ccc2-c3c(C4(c2c1)CCCC4)cc(cc3)c1ccccc1\tlow_energy/ph_fluorene_cp_phenyl_idp_8_1_m062x.log\n",
      "File: ph_35pr_41_1_m062x.log, SMILES: CCCc1cc(CCC)cc(c1)c1ccccc1\tlow_energy/ph_35pr_41_1_m062x.log\n",
      "File: ph_35iprf_6_1_m062x.log, SMILES: FC(C(C(F)(F)F)(c1cc(cc(c1)c1ccccc1)C(C(F)(F)F)(C(F)(F)F)F)F)(F)F\tlow_energy/ph_35iprf_6_1_m062x.log\n",
      "File: ph_35hex_154_1_m062x.log, SMILES: CCCCCCc1cc(CCCCCC)cc(c1)c1ccccc1\tlow_energy/ph_35hex_154_1_m062x.log\n",
      "File: ph_fluorene_cp_tbutyl_10_1_m062x.log, SMILES: CC(c1ccc2-c3c(C4(c2c1)CCCC4)cc(cc3)c1ccccc1)(C)C\tlow_energy/ph_fluorene_cp_tbutyl_10_1_m062x.log\n",
      "File: ph_fluorene_cp_7_1_m062x.log, SMILES: c1ccc(cc1)c1ccc2-c3c(C4(c2c1)CCCC4)cccc3\tlow_energy/ph_fluorene_cp_7_1_m062x.log\n",
      "File: ph_35me_2_1_m062x.log, SMILES: Cc1cc(C)cc(c1)c1ccccc1\tlow_energy/ph_35me_2_1_m062x.log\n",
      "File: ph_345me_1_1_m062x.log, SMILES: Cc1cc(cc(c1C)C)c1ccccc1\tlow_energy/ph_345me_1_1_m062x.log\n",
      "File: ph_3ph4cf3_8_1_m062x.log, SMILES: FC(c1ccc(cc1)c1cccc(c1)c1ccccc1)(F)F\tlow_energy/ph_3ph4cf3_8_1_m062x.log\n",
      "File: ph_35isopbutyl_38_1_m062x.log, SMILES: CC(CCc1cc(CCC(C)C)cc(c1)c1ccccc1)C\tlow_energy/ph_35isopbutyl_38_1_m062x.log\n",
      "File: ph_2phenanthryl_2_1_m062x.log, SMILES: c1ccc(cc1)c1ccc2c(c1)ccc1c2cccc1\tlow_energy/ph_2phenanthryl_2_1_m062x.log\n",
      "File: ph3ph35cf3_3_1_m062x.log, SMILES: FC(c1cc(cc(c1)c1ccc(cc1)c1ccccc1)C(F)(F)F)(F)F\tlow_energy/ph3ph35cf3_3_1_m062x.log\n",
      "File: ph35sf5_idp_7_1_m062x.log, SMILES: FS(c1cc(cc(c1)S(F)(F)(F)(F)F)c1ccccc1)(F)(F)(F)F\tlow_energy/ph35sf5_idp_7_1_m062x.log\n",
      "File: ph_fluorene_cp_methyl_idp_8_1_m062x.log, SMILES: Cc1ccc2-c3c(C4(c2c1)CCCC4)cc(cc3)c1ccccc1\tlow_energy/ph_fluorene_cp_methyl_idp_8_1_m062x.log\n",
      "File: ph_fluorene_cp_methyl_idp_1_1_m062x.log, SMILES: Cc1ccc2-c3c(C4(c2c1)CCCC4)cc(cc3)c1ccccc1\tlow_energy/ph_fluorene_cp_methyl_idp_1_1_m062x.log\n",
      "File: ph4sf5_2_1_m062x.log, SMILES: FS(c1ccc(cc1)c1ccccc1)(F)(F)(F)F\tlow_energy/ph4sf5_2_1_m062x.log\n"
     ]
    }
   ],
   "source": [
    "def process_files_in_folder(folder_path):\n",
    "    try:\n",
    "        for filename in os.listdir(folder_path):\n",
    "            if filename.endswith(\".log\"):\n",
    "                file_path = os.path.join(folder_path, filename)\n",
    "                \n",
    "                try:\n",
    "                    smiles_string = gaussian_output_to_smiles(file_path)\n",
    "                    if smiles_string:\n",
    "                        print(f\"File: {filename}, SMILES: {smiles_string}\")\n",
    "                except Exception as e:\n",
    "                    print(f\"An error occurred processing file {filename}: {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "\n",
    "# Replace 'your_folder_path' with the actual path to your folder containing .log files\n",
    "folder_path = 'low_energy'\n",
    "\n",
    "process_files_in_folder(folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File: ph4cf3_idp_2_1_m062x.log, SMILES: FC(c1ccc(cc1))(F)F\tlow_energy/ph4cf3_idp_2_1_m062x.log\n",
      "File: ph_fluorene_methyl_1_1_m062x.log, SMILES: CC1(C)c2cc(ccc2-c2c1cccc2)\tlow_energy/ph_fluorene_methyl_1_1_m062x.log\n",
      "File: ph_35prf_37_1_m062x.log, SMILES: FC(C(C(c1cc(cc(c1)C(C(C(F)(F)F)(F)F)(F)F))(F)F)(F)F)(F)F\tlow_energy/ph_35prf_37_1_m062x.log\n",
      "File: ph_35et_5_1_m062x.log, SMILES: CCc1cc(CC)cc(c1)\tlow_energy/ph_35et_5_1_m062x.log\n",
      "File: 1naphth_idp_1_1_m062x.log, SMILES: c1ccc(cc1)c1cccc2c1cccc2\tlow_energy/1naphth_idp_1_1_m062x.log\n",
      "File: ph_fluorene_cy_idp_1_1_m062x.log, SMILES: c1ccc(cc1)c1ccc2-c3c(C4(c2c1)CCCCC4)cccc3\tlow_energy/ph_fluorene_cy_idp_1_1_m062x.log\n",
      "File: ph_4ph_3_1_m062x.log, SMILES: c1ccc(cc1)c1ccc(cc1)\tlow_energy/ph_4ph_3_1_m062x.log\n",
      "File: 2naphth_idp_1_1_m062x.log, SMILES: c1ccc(cc1)c1ccc2c(c1)cccc2\tlow_energy/2naphth_idp_1_1_m062x.log\n",
      "File: ph_pyrene_me_1_1_m062x.log, SMILES: Cc1cc(C)c2c3c1ccc1c3c(cc2)cc(c1)\tlow_energy/ph_pyrene_me_1_1_m062x.log\n",
      "File: phenyl_idp_1_1_m062x.log, SMILES: c1ccc(cc1)\tlow_energy/phenyl_idp_1_1_m062x.log\n",
      "File: ph4tbu_idp_1_1_m062x.log, SMILES: CC(c1ccc(cc1))(C)C\tlow_energy/ph4tbu_idp_1_1_m062x.log\n",
      "File: ph35cf3_1_1_m062x.log, SMILES: FC(c1cc(cc(c1))C(F)(F)F)(F)F\tlow_energy/ph35cf3_1_1_m062x.log\n",
      "File: ph_fluorene_cp_nbutyl_63_1_m062x.log, SMILES: CCCCc1ccc2-c3c(C4(c2c1)CCCC4)cc(cc3)\tlow_energy/ph_fluorene_cp_nbutyl_63_1_m062x.log\n",
      "File: ph_4me_2_1_m062x.log, SMILES: Cc1ccc(cc1)\tlow_energy/ph_4me_2_1_m062x.log\n",
      "File: ph_fluorene_cp_phenyl_idp_8_1_m062x.log, SMILES: c1ccc(cc1)c1ccc2-c3c(C4(c2c1)CCCC4)cc(cc3)\tlow_energy/ph_fluorene_cp_phenyl_idp_8_1_m062x.log\n",
      "File: ph_35pr_41_1_m062x.log, SMILES: CCCc1cc(CCC)cc(c1)\tlow_energy/ph_35pr_41_1_m062x.log\n",
      "File: ph_35iprf_6_1_m062x.log, SMILES: FC(C(C(F)(F)F)(c1cc(cc(c1))C(C(F)(F)F)(C(F)(F)F)F)F)(F)F\tlow_energy/ph_35iprf_6_1_m062x.log\n",
      "File: ph_35hex_154_1_m062x.log, SMILES: CCCCCCc1cc(CCCCCC)cc(c1)\tlow_energy/ph_35hex_154_1_m062x.log\n",
      "File: ph_fluorene_cp_tbutyl_10_1_m062x.log, SMILES: CC(c1ccc2-c3c(C4(c2c1)CCCC4)cc(cc3))(C)C\tlow_energy/ph_fluorene_cp_tbutyl_10_1_m062x.log\n",
      "File: ph_fluorene_cp_7_1_m062x.log, SMILES: c1ccc(cc1)c1ccc2-c3c(C4(c2c1)CCCC4)cccc3\tlow_energy/ph_fluorene_cp_7_1_m062x.log\n",
      "File: ph_35me_2_1_m062x.log, SMILES: Cc1cc(C)cc(c1)\tlow_energy/ph_35me_2_1_m062x.log\n",
      "File: ph_345me_1_1_m062x.log, SMILES: Cc1cc(cc(c1C)C)\tlow_energy/ph_345me_1_1_m062x.log\n",
      "File: ph_3ph4cf3_8_1_m062x.log, SMILES: FC(c1ccc(cc1)c1cccc(c1))(F)F\tlow_energy/ph_3ph4cf3_8_1_m062x.log\n",
      "File: ph_35isopbutyl_38_1_m062x.log, SMILES: CC(CCc1cc(CCC(C)C)cc(c1))C\tlow_energy/ph_35isopbutyl_38_1_m062x.log\n",
      "File: ph_2phenanthryl_2_1_m062x.log, SMILES: c1ccc(cc1)c1ccc2c(c1)ccc1c2cccc1\tlow_energy/ph_2phenanthryl_2_1_m062x.log\n",
      "File: ph3ph35cf3_3_1_m062x.log, SMILES: FC(c1cc(cc(c1)c1ccc(cc1))C(F)(F)F)(F)F\tlow_energy/ph3ph35cf3_3_1_m062x.log\n",
      "File: ph35sf5_idp_7_1_m062x.log, SMILES: FS(c1cc(cc(c1)S(F)(F)(F)(F)F))(F)(F)(F)F\tlow_energy/ph35sf5_idp_7_1_m062x.log\n",
      "File: ph_fluorene_cp_methyl_idp_8_1_m062x.log, SMILES: Cc1ccc2-c3c(C4(c2c1)CCCC4)cc(cc3)\tlow_energy/ph_fluorene_cp_methyl_idp_8_1_m062x.log\n",
      "File: ph_fluorene_cp_methyl_idp_1_1_m062x.log, SMILES: Cc1ccc2-c3c(C4(c2c1)CCCC4)cc(cc3)\tlow_energy/ph_fluorene_cp_methyl_idp_1_1_m062x.log\n",
      "File: ph4sf5_2_1_m062x.log, SMILES: FS(c1ccc(cc1))(F)(F)(F)F\tlow_energy/ph4sf5_2_1_m062x.log\n"
     ]
    }
   ],
   "source": [
    "def remove_benzene(smiles):\n",
    "    # Check if the SMILES contains a benzene ring\n",
    "    if 'c1ccccc1' in smiles:\n",
    "        # Replace benzene ring with an empty string\n",
    "        smiles = smiles.replace('c1ccccc1', '')\n",
    "    return smiles\n",
    "\n",
    "def gaussian_output_to_smiles(gaussian_output_file):\n",
    "    try:\n",
    "        # Read Gaussian output file using Open Babel\n",
    "        mol = next(pybel.readfile(\"g09\", gaussian_output_file))\n",
    "        \n",
    "        # Generate SMILES\n",
    "        smiles = mol.write(\"can\").strip()\n",
    "        \n",
    "        # Remove benzene rings\n",
    "        smiles = remove_benzene(smiles)\n",
    "        \n",
    "        return smiles\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        return None\n",
    "\n",
    "def process_files_in_folder(folder_path):\n",
    "    try:\n",
    "        for filename in os.listdir(folder_path):\n",
    "            if filename.endswith(\".log\"):\n",
    "                file_path = os.path.join(folder_path, filename)\n",
    "                \n",
    "                try:\n",
    "                    smiles_string = gaussian_output_to_smiles(file_path)\n",
    "                    if smiles_string:\n",
    "                        print(f\"File: {filename}, SMILES: {smiles_string}\")\n",
    "                except Exception as e:\n",
    "                    print(f\"An error occurred processing file {filename}: {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "\n",
    "folder_path = 'low_energy'\n",
    "\n",
    "process_files_in_folder(folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "expected 'except' or 'finally' block (1385719699.py, line 56)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[1], line 56\u001b[0;36m\u001b[0m\n\u001b[0;31m    \"\"\"except Exception as e:\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m expected 'except' or 'finally' block\n"
     ]
    }
   ],
   "source": [
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "\n",
    "def remove_benzene_from_rdkit(mol):\n",
    "    # Check if the molecule contains a benzene ring\n",
    "    benzene_pattern = Chem.MolFromSmiles('c1ccccc1')\n",
    "    \n",
    "    # Use RDKit's HasSubstructMatch\n",
    "    if mol.HasSubstructMatch(benzene_pattern):\n",
    "        # Remove benzene ring\n",
    "        mol = Chem.DeleteSubstructs(mol, benzene_pattern)\n",
    "    return mol\n",
    "\n",
    "def gaussian_output_to_rdkit(gaussian_output_file):\n",
    "    try:\n",
    "        # Read Gaussian output file using Open Babel\n",
    "        mol_supplier = pybel.readfile(\"g09\", gaussian_output_file)\n",
    "        \n",
    "        # Get the molecule\n",
    "        obmol = next(mol_supplier).OBMol\n",
    "        \n",
    "        # Convert OBMol to RDKit molecule using SMILES\n",
    "        smiles = Chem.ob.MolToSmiles(obmol)\n",
    "        mol = Chem.MolFromSmiles(smiles)\n",
    "        \n",
    "        # Remove benzene rings\n",
    "        mol = remove_benzene_from_rdkit(mol)\n",
    "        \n",
    "        return mol\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        return None\n",
    "\n",
    "def process_files_in_folder(folder_path):\n",
    "    try:\n",
    "        # Load a reference molecule (replace 'reference_smiles' with the actual SMILES)\n",
    "        reference_smiles = 'CCO'\n",
    "        reference_mol = Chem.MolFromSmiles(reference_smiles)\n",
    "\n",
    "        for filename in os.listdir(folder_path):\n",
    "            if filename.endswith(\".log\"):\n",
    "                file_path = os.path.join(folder_path, filename)\n",
    "                \n",
    "                try:\n",
    "                    # Convert Gaussian output to RDKit molecule\n",
    "                    rdkit_mol = gaussian_output_to_rdkit(file_path)\n",
    "                    \n",
    "                    # Check if the conversion was successful\n",
    "                    if rdkit_mol is not None:\n",
    "                        # Compare with the reference molecule\n",
    "                        similarity = AllChem.DataStructs.TanimotoSimilarity(Chem.RDKFingerprint(rdkit_mol), Chem.RDKFingerprint(reference_mol))\n",
    "                    \n",
    "                        print(f\"File: {filename}, Similarity to Reference: {similarity}\")\n",
    "                except Exception as e:\n",
    "                    print(f\"An error occurred processing file {filename}: {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "\n",
    "\n",
    "# Replace 'your_folder_path' with the actual path to your folder containing .log files\n",
    "folder_path = 'low_energy'\n",
    "\n",
    "process_files_in_folder(folder_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def are_molecules_in_second_group(group1_smiles, group2_smiles):\n",
    "    # Convert SMILES to RDKit molecules\n",
    "    group1_molecules = [Chem.MolFromSmiles(smiles) for smiles in group1_smiles]\n",
    "    group2_molecules = [Chem.MolFromSmiles(smiles) for smiles in group2_smiles]\n",
    "\n",
    "    # Check if molecules in group1 are also in group2\n",
    "    molecules_in_both_groups = set(group1_molecules) & set(group2_molecules)\n",
    "\n",
    "    return molecules_in_both_groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25\n",
      "Done! Modified data saved to ../Desktop/MS/si_repository 2/data/processed/IDPiDataset_noI.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy\n",
    "# Function to remove 'I' from a string\n",
    "def remove_i_from_string(s):\n",
    "    return s.replace('I', '')\n",
    "\n",
    "# Input and output file paths\n",
    "input_file = '../Desktop/MS/si_repository 2/data/processed/IDPiDataset.xlsx'\n",
    "output_file = '../Desktop/MS/si_repository 2/data/processed/IDPiDataset_noI.xlsx'\n",
    "\n",
    "# Specify the column number (0-based index) containing strings\n",
    "column_to_modify = \"3,3â€™ Catalyst Substituent \"\n",
    "# Read the CSV file into a DataFrame\n",
    "df = pd.read_excel(input_file)\n",
    "print(len(np.unique(df[column_to_modify])))# Remove 'I' from the specified column\n",
    "df[column_to_modify] = df[column_to_modify].str.replace('(I)', '')\n",
    "df[column_to_modify] = df[column_to_modify].str.replace('I', '')\n",
    "\n",
    "# Save the modified data to a new Excel file\n",
    "df.to_excel(output_file, index=False)\n",
    "\n",
    "\n",
    "print(f'Done! Modified data saved to {output_file}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Input Excel file with SMILES data and output folder for PNGs\n",
    "input_file = 'input.xlsx'\n",
    "output_folder = '../..Desktop/MS/si_repository 2/data'\n",
    "\n",
    "# Specify the column name containing SMILES strings\n",
    "column_name =  \"3,3â€™ Catalyst Substituent \"\n",
    "# Replace with the actual column name\n",
    "\n",
    "# Read the Excel file into a DataFrame\n",
    "df = pd.read_excel(output_file)\n",
    "\n",
    "# Ensure the output folder exists\n",
    "import os\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Iterate through unique SMILES strings in the specified column\n",
    "unique_smiles = df[column_name].unique()\n",
    "len(unique_smiles)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import math\n",
    "\n",
    "def calculate_distance(point1, point2):\n",
    "    return math.sqrt((point1[0] - point2[0])**2 + (point1[1] - point2[1])**2 + (point1[2] - point2[2])**2)\n",
    "\n",
    "def calculate_max_distance(coordinates):\n",
    "    max_distance = 0.0\n",
    "    \n",
    "    # Use itertools to generate all combinations of points\n",
    "    for pair in itertools.combinations(coordinates, 2):\n",
    "        distance = calculate_distance(pair[0], pair[1])\n",
    "        max_distance = max(max_distance, distance)\n",
    "    \n",
    "    return max_distance\n",
    "\n",
    "\n",
    "def calculate_bounding_box_dimensions(coordinates):\n",
    "    min_x, min_y, min_z = float('inf'), float('inf'), float('inf')\n",
    "    max_x, max_y, max_z = float('-inf'), float('-inf'), float('-inf')\n",
    "\n",
    "    for point in coordinates:\n",
    "        x, y, z = point\n",
    "        min_x = min(min_x, x)\n",
    "        min_y = min(min_y, y)\n",
    "        min_z = min(min_z, z)\n",
    "        max_x = max(max_x, x)\n",
    "        max_y = max(max_y, y)\n",
    "        max_z = max(max_z, z)\n",
    "\n",
    "    dimensions = [max_x - min_x, max_y - min_y, max_z - min_z]\n",
    "    dimensions.sort(reverse=True)\n",
    "\n",
    "    return dimensions\n",
    "\n",
    "def read_coordinates_from_log(log_file_path):\n",
    "    coordinates = []\n",
    "\n",
    "    with open(log_file_path, 'r') as log_file:\n",
    "        lines = log_file.readlines()\n",
    "\n",
    "        # Find the last occurrence of the start index\n",
    "        start_index = next(i for i, line in reversed(list(enumerate(lines))) if \" Center     Atomic      Atomic             Coordinates (Angstroms)\" in line) + 3\n",
    "\n",
    "        # Find the end index\n",
    "        end_index = lines.index(\" ---------------------------------------------------------------------\\n\", start_index)\n",
    "        print(start_index-end_index)\n",
    "        # Extract and parse the coordinates\n",
    "        for line in lines[start_index:end_index]:\n",
    "            \n",
    "            values = line.split()\n",
    "            if len(values) == 6:\n",
    "                # Extract x, y, z coordinates and convert to floats\n",
    "                x, y, z = map(float, values[3:])\n",
    "                coordinates.append((x, y, z))\n",
    "\n",
    "    return coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-25\n",
      "-39\n",
      "-40\n",
      "-34\n",
      "-28\n",
      "-46\n",
      "-32\n",
      "-28\n",
      "-40\n",
      "-42\n",
      "-22\n",
      "-34\n",
      "-28\n",
      "-55\n",
      "-25\n",
      "-40\n",
      "-53\n",
      "-40\n",
      "-40\n",
      "-58\n",
      "-55\n",
      "-43\n",
      "-28\n",
      "-31\n",
      "-35\n",
      "-52\n",
      "-34\n",
      "-38\n",
      "-32\n",
      "-46\n",
      "-46\n",
      "-46\n",
      "-27\n"
     ]
    }
   ],
   "source": [
    "def process_files_in_folder(folder_path):\n",
    "    results = []\n",
    "\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith(\".log\"):\n",
    "            file_path = os.path.join(folder_path, filename)\n",
    "\n",
    "            try:\n",
    "                # Extract coordinates from the .log file\n",
    "                coordinates = read_coordinates_from_log(file_path)\n",
    "\n",
    "                # Apply the functions\n",
    "                max_distance = calculate_max_distance(coordinates)\n",
    "                bounding_box_dimensions = calculate_bounding_box_dimensions(coordinates)\n",
    "\n",
    "                # Save the results\n",
    "                result_entry = {'filename': filename, 'max_distance': max_distance, 'dimensions': bounding_box_dimensions}\n",
    "                results.append(result_entry)\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"An error occurred processing file {filename}: {e}\")\n",
    "\n",
    "    return results\n",
    "\n",
    "# Replace 'your_folder_path' with the actual path to your folder containing .log files\n",
    "folder_path = 'low_energy'\n",
    "\n",
    "results = process_files_in_folder(folder_path)\n",
    "\n",
    "# Save results to a text file\n",
    "output_file_path = 'results_dist.txt'\n",
    "with open(output_file_path, 'w') as output_file:\n",
    "    for result in results:\n",
    "        output_file.write(f\"File: {result['filename']}, {result['max_distance']}, {result['dimensions'][0]}, {result['dimensions'][1]}, {result['dimensions'][2]}\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
